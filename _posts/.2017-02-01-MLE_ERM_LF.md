---
title: "Maximum Likelihood Estimation, Empirical Risk Minimization and Loss functions"
excerpt_separator: "<!--more-->"
categories:
  - Machine Learning
tags:
  - Maximum Likelihood
  - Empirical Risk Minimization
  - Loss Function
  - Machine Learning
mathjax: true
---

# Why this post

A lot of machine learning newbies (including myself) got confused when we were introduced to a couple of fancy terms in this field. One example is the relationship (and difference) between maximum likelihood estimation (MLE), empirical risk minimization (ERM) and loss functions. It took me a while to Google, read textbooks and discuss with classmates before I came to a more intuitive understanding of these things, and sadly as you can tell from my efforts above, there was not a concise yet clear solution readily available now. That's what motivates me to write this post and share it here.

# Maximum Likelihood Estimation -- A motivating example

New York's weather is really really bad these days. Being a lazy student, the probability that I will go to school when


**Maximum Likelihood Estimation (MLE)** is a concept closely related to parametric statistical model. Suppose we have observed $$x$$, and we would like to fit it to a certain parametric model $$\mathcal{P}$$.
